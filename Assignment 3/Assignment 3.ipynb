{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOOOWzXgxcExpLqxlymmqJH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# 26 Nov 2023\n","# CSC461 – Assignment3 – Machine Learning\n","# Muhammad Ammar Mukhtar\n","# FA21-BSE-141\n","# In this assignment, we have implimented different Machine Learnin Algorithms on dataset"],"metadata":{"id":"KwlEThhCyyBP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Question 1**"],"metadata":{"id":"duwRDk1F0AaI"}},{"cell_type":"markdown","source":["1. How many instances does the dataset contain?\n","        110\n","2. How many input attributes does the dataset contain?\n","        7 input instances\n","3. How many possible values does the output attribute have?\n","        There is one output attribute \"gender\" which have two values \"male and female\".\n","4. How many input attributes are categorical?\n","        Beard, Hair length, Scarf, Eye color ar categorical attributes.\n","5. What is the class ratio (male vs female) in the dataset?\n","        62 are males and 48 are females."],"metadata":{"id":"OIMne8jSxMLe"}},{"cell_type":"markdown","source":["**Question 2**"],"metadata":{"id":"qA2Vif670dSe"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming 'data' is your DataFrame with the specified columns\n","file_path = 'gender-prediction.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","data = pd.read_csv(file_path)\n","\n","# Encode categorical attributes\n","le = LabelEncoder()\n","data[\"beard\"] = le.fit_transform(data[\"beard\"])\n","data[\"hair_length\"] = le.fit_transform(data[\"hair_length\"])\n","data[\"scarf\"] = le.fit_transform(data[\"scarf\"])\n","data[\"eye_color\"] = le.fit_transform(data[\"eye_color\"])\n","data[\"gender\"] = le.fit_transform(data[\"gender\"])\n","\n","# Select input features and output\n","X = data[[\"height\", \"weight\", \"beard\", \"hair_length\", \"shoe_size\", \"scarf\", \"eye_color\"]]\n","y = data[\"gender\"]\n","\n","# Split the data into training and testing sets (2/3 train and 1/3 test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","\n","# Initialize models\n","logreg = LogisticRegression()\n","svm = SVC()\n","mlp = MLPClassifier()\n","\n","# Train models\n","logreg.fit(X_train, y_train)\n","svm.fit(X_train, y_train)\n","mlp.fit(X_train, y_train)\n","\n","# Make predictions\n","logreg_preds = logreg.predict(X_test)\n","svm_preds = svm.predict(X_test)\n","mlp_preds = mlp.predict(X_test)\n","\n","# Evaluate models\n","logreg_accuracy = accuracy_score(y_test, logreg_preds)\n","svm_accuracy = accuracy_score(y_test, svm_preds)\n","mlp_accuracy = accuracy_score(y_test, mlp_preds)\n","\n","# Print accuracies\n","print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n","print(\"Support Vector Machine Accuracy:\", svm_accuracy)\n","print(\"Multilayer Perceptron Accuracy:\", mlp_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQivfHXwl-BW","executionInfo":{"status":"ok","timestamp":1701011693149,"user_tz":-300,"elapsed":1942,"user":{"displayName":"MUHAMMAD AMMAR MUKHTAR","userId":"18133610323232038528"}},"outputId":"f13368d1-0662-4b5e-a0b5-e7158caca5d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy: 0.8648648648648649\n","Support Vector Machine Accuracy: 0.7567567567567568\n","Multilayer Perceptron Accuracy: 0.8648648648648649\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["1. How many instances are incorrectly classified?\n","        By Logistic Regression : 16\n","        Support Vector Machine : 28\n","        Multilayer Perceptron : 15"],"metadata":{"id":"G-qHrqc_1o1q"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming 'data' is your DataFrame with the specified columns\n","file_path = 'gender-prediction.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","data = pd.read_csv(file_path)\n","\n","# Encode categorical attributes\n","le = LabelEncoder()\n","data[\"beard\"] = le.fit_transform(data[\"beard\"])\n","data[\"hair_length\"] = le.fit_transform(data[\"hair_length\"])\n","data[\"scarf\"] = le.fit_transform(data[\"scarf\"])\n","data[\"eye_color\"] = le.fit_transform(data[\"eye_color\"])\n","data[\"gender\"] = le.fit_transform(data[\"gender\"])\n","\n","# Select input features and output\n","X = data[[\"height\", \"weight\", \"beard\", \"hair_length\", \"shoe_size\", \"scarf\", \"eye_color\"]]\n","y = data[\"gender\"]\n","\n","# Split the data into training and testing sets (80% train and 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n","\n","# Initialize models\n","logreg = LogisticRegression()\n","svm = SVC()\n","mlp = MLPClassifier()\n","\n","# Train models\n","logreg.fit(X_train, y_train)\n","svm.fit(X_train, y_train)\n","mlp.fit(X_train, y_train)\n","\n","# Make predictions\n","logreg_preds = logreg.predict(X_test)\n","svm_preds = svm.predict(X_test)\n","mlp_preds = mlp.predict(X_test)\n","\n","# Evaluate models\n","logreg_accuracy = accuracy_score(y_test, logreg_preds)\n","svm_accuracy = accuracy_score(y_test, svm_preds)\n","mlp_accuracy = accuracy_score(y_test, mlp_preds)\n","\n","# Print accuracies\n","print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n","print(\"Support Vector Machine Accuracy:\", svm_accuracy)\n","print(\"Multilayer Perceptron Accuracy:\", mlp_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UC5znGzRmZCG","executionInfo":{"status":"ok","timestamp":1701001679038,"user_tz":-300,"elapsed":426,"user":{"displayName":"MUHAMMAD AMMAR MUKHTAR","userId":"18133610323232038528"}},"outputId":"04fb14fb-de0b-4197-a711-4d1bd9b07a28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy: 1.0\n","Support Vector Machine Accuracy: 0.8181818181818182\n","Multilayer Perceptron Accuracy: 0.45454545454545453\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}]},{"cell_type":"markdown","source":["2. Rerun the experiment using train/test split ratio of 80/20. Do you see any change in the results? Explain.\n","        If we increase the training set then accuracy of Machine Learning model increase excluding Multilayer Preceptron Accuracy.\n","\n","3. Name 2 attributes that you believe are the most “powerful” in the prediction task. Explain why?\n","        Beard and Scarf are the most powerful attributes of the dataset because when an instance has beard then it is a male and when it has scarf then it is female."],"metadata":{"id":"ov8iy_-i05l2"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Assuming 'data' is your DataFrame with the specified columns\n","file_path = 'gender-prediction.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","data = pd.read_csv(file_path)\n","\n","# Encode categorical attributes\n","le = LabelEncoder()\n","data[\"beard\"] = le.fit_transform(data[\"beard\"])\n","data[\"hair_length\"] = le.fit_transform(data[\"hair_length\"])\n","data[\"scarf\"] = le.fit_transform(data[\"scarf\"])\n","data[\"eye_color\"] = le.fit_transform(data[\"eye_color\"])\n","data[\"gender\"] = le.fit_transform(data[\"gender\"])\n","\n","# Select input features and output\n","X = data[[\"height\", \"weight\", \"hair_length\", \"shoe_size\", \"eye_color\"]]\n","y = data[\"gender\"]\n","\n","# Split the data into training and testing sets (80% train and 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n","\n","# Initialize models\n","logreg = LogisticRegression()\n","svm = SVC()\n","mlp = MLPClassifier()\n","\n","# Train models\n","logreg.fit(X_train, y_train)\n","svm.fit(X_train, y_train)\n","mlp.fit(X_train, y_train)\n","\n","# Make predictions\n","logreg_preds = logreg.predict(X_test)\n","svm_preds = svm.predict(X_test)\n","mlp_preds = mlp.predict(X_test)\n","\n","# Evaluate models\n","logreg_accuracy = accuracy_score(y_test, logreg_preds)\n","svm_accuracy = accuracy_score(y_test, svm_preds)\n","mlp_accuracy = accuracy_score(y_test, mlp_preds)\n","\n","# Print accuracies\n","print(\"Logistic Regression Accuracy:\", logreg_accuracy)\n","print(\"Support Vector Machine Accuracy:\", svm_accuracy)\n","print(\"Multilayer Perceptron Accuracy:\", mlp_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROes7_u4nmak","executionInfo":{"status":"ok","timestamp":1701002021785,"user_tz":-300,"elapsed":569,"user":{"displayName":"MUHAMMAD AMMAR MUKHTAR","userId":"18133610323232038528"}},"outputId":"10cf02b1-ef81-4230-9bad-b8c5735e9542"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy: 1.0\n","Support Vector Machine Accuracy: 0.8181818181818182\n","Multilayer Perceptron Accuracy: 0.7272727272727273\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["4. Try to exclude these 2 attribute(s) from the dataset. Rerun the experiment (using 80/20 train/test split), did you find any change in the results? Explain.\n","        After excluding two powerful attributes, the accuracy of Multilayer Preceptron Machine Learning Algorithm is increased."],"metadata":{"id":"-AhwdEZg3v0r"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import cross_val_score, ShuffleSplit, LeavePOut\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import make_scorer, f1_score\n","\n","# Assuming 'data' is your DataFrame with the specified columns\n","file_path = 'gender-prediction.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","data = pd.read_csv(file_path)\n","\n","# Encode categorical attributes\n","le = LabelEncoder()\n","data[\"beard\"] = le.fit_transform(data[\"beard\"])\n","data[\"hair_length\"] = le.fit_transform(data[\"hair_length\"])\n","data[\"scarf\"] = le.fit_transform(data[\"scarf\"])\n","data[\"eye_color\"] = le.fit_transform(data[\"eye_color\"])\n","data[\"gender\"] = le.fit_transform(data[\"gender\"])\n","\n","# Select input features and output\n","X = data[[\"height\", \"weight\", \"beard\", \"hair_length\", \"shoe_size\", \"scarf\", \"eye_color\"]]\n","y = data[\"gender\"]\n","\n","# Initialize the Random Forest classifier\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Define F1 score as the scoring metric\n","f1_scorer = make_scorer(f1_score, average='weighted')\n","\n","# Monte Carlo Cross-Validation\n","monte_carlo_cv = ShuffleSplit(n_splits=5, test_size=0.33, random_state=42)\n","monte_carlo_f1_scores = cross_val_score(rf_classifier, X, y, cv=monte_carlo_cv, scoring=f1_scorer)\n","\n","# Leave P-Out Cross-Validation\n","leave_p_out_cv = LeavePOut(p=1)  # You can adjust 'p' based on your preference\n","leave_p_out_f1_scores = cross_val_score(rf_classifier, X, y, cv=leave_p_out_cv, scoring=f1_scorer)\n","\n","# Print F1 scores\n","print(\"Monte Carlo Cross-Validation F1 Scores:\", monte_carlo_f1_scores)\n","print(\"Leave P-Out Cross-Validation F1 Scores:\", leave_p_out_f1_scores)\n"],"metadata":{"id":"PmtZYK7Yo71e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701018342254,"user_tz":-300,"elapsed":20387,"user":{"displayName":"MUHAMMAD AMMAR MUKHTAR","userId":"18133610323232038528"}},"outputId":"75ee71d4-fed1-48b3-d704-66dddf66297c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Monte Carlo Cross-Validation F1 Scores: [0.97293337 0.94594595 0.97285132 1.         0.97285132]\n","Leave P-Out Cross-Validation F1 Scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Assuming 'data' is your DataFrame with the specified columns, including the newly added 10 instances\n","file_path = '10-new-gender-prediction.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","data = pd.read_csv(file_path)\n","\n","# Encode categorical attributes\n","le = LabelEncoder()\n","data[\"beard\"] = le.fit_transform(data[\"beard\"])\n","data[\"hair_length\"] = le.fit_transform(data[\"hair_length\"])\n","data[\"scarf\"] = le.fit_transform(data[\"scarf\"])\n","data[\"eye_color\"] = le.fit_transform(data[\"eye_color\"])\n","data[\"gender\"] = le.fit_transform(data[\"gender\"])\n","\n","# Select input features and output\n","X = data[[\"height\", \"weight\", \"beard\", \"hair_length\", \"shoe_size\", \"scarf\", \"eye_color\"]]\n","y = data[\"gender\"]\n","\n","# Initialize the Gaussian Naïve Bayes classifier\n","gnb_classifier = GaussianNB()\n","\n","# Train the model on the entire dataset\n","gnb_classifier.fit(X, y)\n","\n","# Assuming 'new_instances' is your DataFrame with the specified columns, newly added 10 instances\n","file_path = 'new-instances.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","new_instances = pd.read_csv(file_path)\n","\n","# Assuming 'new_instances' is a DataFrame with the 10 new instances\n","\n","# Make predictions on the new instances\n","new_instances_X = new_instances[[\"height\", \"weight\", \"beard\", \"hair_length\", \"shoe_size\", \"scarf\", \"eye_color\"]]\n","new_instances_y_true = new_instances[\"gender\"]\n","new_instances_y_pred = gnb_classifier.predict(new_instances_X)\n","\n","# Evaluate the model on the new instances\n","accuracy = accuracy_score(new_instances_y_true, new_instances_y_pred)\n","precision = precision_score(new_instances_y_true, new_instances_y_pred, average='weighted')\n","recall = recall_score(new_instances_y_true, new_instances_y_pred, average='weighted')\n","\n","# Print evaluation scores\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"t-zP9PvRlWJ4","executionInfo":{"status":"error","timestamp":1701020307684,"user_tz":-300,"elapsed":26,"user":{"displayName":"MUHAMMAD AMMAR MUKHTAR","userId":"18133610323232038528"}},"outputId":"c6de848e-0185-4167-a835-79d4102eba58"},"execution_count":18,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-d937393e29db>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mnew_instances_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_instances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"beard\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hair_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shoe_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scarf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eye_color\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mnew_instances_y_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_instances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mnew_instances_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_instances_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Evaluate the model on the new instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;34m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     def __array_wrap__(\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'yes'"]}]}]}