{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**"
      ],
      "metadata": {
        "id": "7cR8LTgi4jpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4pY22Czze5l",
        "outputId": "cc1e6df3-692a-4d63-bd0e-628e2db4aba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words (BoW):\n",
            "   analysis  best  computer  courses  data  important  in  is  most  of  one  \\\n",
            "0         0     0         1        1     1          1   1   1     1   1    1   \n",
            "1         0     1         0        1     1          0   0   1     0   1    1   \n",
            "2         1     0         0        0     2          0   0   0     0   0    0   \n",
            "\n",
            "   perform  science  scientists  the  this  \n",
            "0        0        2           0    1     0  \n",
            "1        0        1           0    1     1  \n",
            "2        1        0           1    1     0  \n",
            "\n",
            "Term Frequency (TF):\n",
            "   analysis      best  computer   courses      data  important        in  \\\n",
            "0  0.000000  0.000000  0.267261  0.267261  0.267261   0.267261  0.267261   \n",
            "1  0.000000  0.333333  0.000000  0.333333  0.333333   0.000000  0.000000   \n",
            "2  0.353553  0.000000  0.000000  0.000000  0.707107   0.000000  0.000000   \n",
            "\n",
            "         is      most        of       one   perform   science  scientists  \\\n",
            "0  0.267261  0.267261  0.267261  0.267261  0.000000  0.534522    0.000000   \n",
            "1  0.333333  0.000000  0.333333  0.333333  0.000000  0.333333    0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.353553  0.000000    0.353553   \n",
            "\n",
            "        the      this  \n",
            "0  0.267261  0.000000  \n",
            "1  0.333333  0.333333  \n",
            "2  0.353553  0.000000  \n",
            "\n",
            "Inverse Document Frequency (IDF):\n",
            "   analysis      best  computer   courses      data  important        in  \\\n",
            "0  0.000000  0.000000  0.327476  0.249054  0.193412   0.327476  0.327476   \n",
            "1  0.000000  0.422968  0.000000  0.321678  0.249812   0.000000  0.000000   \n",
            "2  0.459115  0.000000  0.000000  0.000000  0.542321   0.000000  0.000000   \n",
            "\n",
            "         is      most        of       one   perform   science  scientists  \\\n",
            "0  0.249054  0.327476  0.249054  0.249054  0.000000  0.498107    0.000000   \n",
            "1  0.321678  0.000000  0.321678  0.321678  0.000000  0.321678    0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.459115  0.000000    0.459115   \n",
            "\n",
            "        the      this  \n",
            "0  0.193412  0.000000  \n",
            "1  0.249812  0.422968  \n",
            "2  0.271161  0.000000  \n",
            "\n",
            "TF-IDF:\n",
            "   analysis      best  computer   courses      data  important        in  \\\n",
            "0  0.000000  0.000000  0.327476  0.249054  0.193412   0.327476  0.327476   \n",
            "1  0.000000  0.422968  0.000000  0.321678  0.249812   0.000000  0.000000   \n",
            "2  0.459115  0.000000  0.000000  0.000000  0.542321   0.000000  0.000000   \n",
            "\n",
            "         is      most        of       one   perform   science  scientists  \\\n",
            "0  0.249054  0.327476  0.249054  0.249054  0.000000  0.498107    0.000000   \n",
            "1  0.321678  0.000000  0.321678  0.321678  0.000000  0.321678    0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.459115  0.000000    0.459115   \n",
            "\n",
            "        the      this  \n",
            "0  0.193412  0.000000  \n",
            "1  0.249812  0.422968  \n",
            "2  0.271161  0.000000  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Define the sentences S1, S2, S3\n",
        "sentences = [\n",
        "    \"data science is one of the most important courses in computer science\",\n",
        "    \"this is one of the best data science courses\",\n",
        "    \"the data scientists perform data analysis\"\n",
        "]\n",
        "\n",
        "# Bag of Words (BoW)\n",
        "vectorizer_bow = CountVectorizer()\n",
        "bow_matrix = vectorizer_bow.fit_transform(sentences)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer_bow.get_feature_names_out())\n",
        "print(\"Bag of Words (BoW):\")\n",
        "print(bow_df)\n",
        "\n",
        "# Term Frequency (TF)\n",
        "vectorizer_tf = TfidfVectorizer(use_idf=False)\n",
        "tf_matrix = vectorizer_tf.fit_transform(sentences)\n",
        "tf_df = pd.DataFrame(tf_matrix.toarray(), columns=vectorizer_tf.get_feature_names_out())\n",
        "print(\"\\nTerm Frequency (TF):\")\n",
        "print(tf_df)\n",
        "\n",
        "# Inverse Document Frequency (IDF)\n",
        "vectorizer_idf = TfidfVectorizer(use_idf=True)\n",
        "idf_matrix = vectorizer_idf.fit_transform(sentences)\n",
        "idf_df = pd.DataFrame(idf_matrix.toarray(), columns=vectorizer_idf.get_feature_names_out())\n",
        "print(\"\\nInverse Document Frequency (IDF):\")\n",
        "print(idf_df)\n",
        "\n",
        "# TF-IDF\n",
        "vectorizer_tfidf = TfidfVectorizer(use_idf=True)\n",
        "tfidf_matrix = vectorizer_tfidf.fit_transform(sentences)\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer_tfidf.get_feature_names_out())\n",
        "print(\"\\nTF-IDF:\")\n",
        "print(tfidf_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**"
      ],
      "metadata": {
        "id": "VSB4If6G43CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, manhattan_distances, euclidean_distances\n",
        "\n",
        "# Define the sentences S1, S2, S3\n",
        "sentences = [\n",
        "    \"data science is one of the most important courses in computer science\",\n",
        "    \"this is one of the best data science courses\",\n",
        "    \"the data scientists perform data analysis\"\n",
        "]\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "# Compute distances\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "manhattan_dist = manhattan_distances(tfidf_matrix)\n",
        "euclidean_dist = euclidean_distances(tfidf_matrix)\n",
        "\n",
        "# Display the results\n",
        "print(\"Cosine Similarity:\")\n",
        "print(cosine_sim)\n",
        "\n",
        "print(\"\\nManhattan Distance:\")\n",
        "print(manhattan_dist)\n",
        "\n",
        "print(\"\\nEuclidean Distance:\")\n",
        "print(euclidean_dist)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0rgDcob3kZI",
        "outputId": "9368799e-5106-4f30-9a76-aabd72b1193a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity:\n",
            "[[1.         0.57732419 0.15733751]\n",
            " [0.57732419 1.         0.20321737]\n",
            " [0.15733751 0.20321737 1.        ]]\n",
            "\n",
            "Manhattan Distance:\n",
            "[[0.         2.73556468 4.60822682]\n",
            " [2.73556468 0.         4.14553005]\n",
            " [4.60822682 4.14553005 0.        ]]\n",
            "\n",
            "Euclidean Distance:\n",
            "[[0.         0.91943005 1.29820067]\n",
            " [0.91943005 0.         1.26236494]\n",
            " [1.29820067 1.26236494 0.        ]]\n"
          ]
        }
      ]
    }
  ]
}