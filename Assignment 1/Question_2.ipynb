{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1jy6cTtqstHOVXMQkrsztR1c7T_cH3t78","authorship_tag":"ABX9TyO49XjOMbRmbPwHpTp5sPHW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBU9RtcB_ixy","executionInfo":{"status":"ok","timestamp":1695062227407,"user_tz":420,"elapsed":8770,"user":{"displayName":"MUHAMMAD AMMAR MUKHTAR","userId":"18133610323232038528"}},"outputId":"bfc01575-3ae5-4c7a-f965-56bee9d70bfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error from website....\n"]}],"source":["# 18 September 2023\n","# CSC461 – Assignment1 – Web Scraping\n","# Muhammad Ammar Mukhtar\n","# FA21-BSE-141 (Section C)\n","# this code will scrap movies details from 'date and time' and 'britannica' website and export details to text file\n","\n","from bs4 import BeautifulSoup\n","import requests\n","import time\n","import pandas as pd\n","\n","share_date = []\n","\n","response = requests.get(\"https://www.timeanddate.com/on-this-day/june/5\", headers={\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/12.0\"})\n","if response.status_code == 200:\n","  soup = BeautifulSoup(response.content, \"html5lib\")\n","  birth_share_name = soup.find('div', {\"class\":\"otd-life__block\"})\n","  #print(birth_share_name.txt)\n","  output = birth_share_name.text\n","  with open(output, \"w\", encoding=\"utf-8\") as text_file:\n","      text_file.write(output)\n","else:\n","  print(\"Error from website....\")\n","\n","\n","# 18 September 2023\n","# CSC461 – Assignment1 – Web Scraping\n","# Muhammad Ammar Mukhtar\n","# FA21-BSE-141 (Section C)\n","# this code will scrap movies details from 'date and time' and 'britannica' website and export details to text file\n","\n","from bs4 import BeautifulSoup\n","import requests\n","import time\n","import pandas as pd\n","\n","share_date = []\n","\n","response = requests.get(\"https://www.britannica.com/on-this-day/June-5\", headers={\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/12.0\"})\n","if response.status_code == 200:\n","  soup = BeautifulSoup(response.content, \"html5lib\")\n","  event = soup.find_all('div', {\"class\":\"card-body font-serif\"})\n","  #for i in event:\n","    #print(i.text.strip())\n","  for i in event:\n","    output2= \"\"+i.text\n","\n","  with open(file1.txt, \"a\", encoding=\"utf-8\") as text_file:\n","      text_file.write(output2)\n","\n","\n","else:\n","  print(\"Error from website....\")\n","\n","\n"]}]}